#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import streamlit as st
from dotenv import load_dotenv
import wikipedia
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import WikipediaLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain import hub
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# í™˜ê²½ ì„¤ì •
load_dotenv()

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë¦¬ë²„í’€ FC RAG ê²€ìƒ‰",
    page_icon="âš½",
    layout="wide"
)

@st.cache_resource
def initialize_rag_system():
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ìºì‹œ ì ìš©)"""
    try:
        # 1. LLM ì„¤ì •
        model_name = os.getenv("CHAT_MODEL", "gpt-4o-mini")
        llm = ChatOpenAI(model=model_name, temperature=0)
        # 2. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        model_name = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
        embeddings = OpenAIEmbeddings(model=model_name)

        # 3. ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ë¦¬ë²„í’€ FC ê´€ë ¨ ë¬¸ì„œ ë¡œë“œ
        topics = [
            "Liverpool F.C.",
            "Liverpool F.C. players",
            "Liverpool F.C. history", 
        ]
        
        all_documents = []
        for topic in topics:
            try:
                loader = WikipediaLoader(
                    query=topic, 
                    lang="en",
                    load_max_docs=2,
                    doc_content_chars_max=3000
                )
                documents = loader.load()
                all_documents.extend(documents)
            except Exception as e:
                st.warning(f"'{topic}' ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        if not all_documents:
            st.error("ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        # 4. í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        split_documents = text_splitter.split_documents(all_documents)
        
        # 5. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
        db = Chroma.from_documents(
            documents=split_documents, 
            embedding=embeddings,
            persist_directory="./chroma_db"
        )
        
        # 6. ê²€ìƒ‰ê¸° ì„¤ì •
        retriever = db.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 5, "fetch_k": 20, "lambda_mult": 0.5}
        )
        
        # 7. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        prompt_template = hub.pull("langchain-ai/retrieval-qa-chat")
        
        # 8. ì¶œë ¥ íŒŒì„œ
        parser = StrOutputParser()
        
        # 9. RAG ì²´ì¸ êµ¬ì„±
        rag_chain = {
            "context": retriever,
            "input": RunnablePassthrough()
        } | prompt_template | llm | parser
        
        return rag_chain, len(split_documents)
        
    except Exception as e:
        st.error(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return None

def main():
    st.title("âš½ ë¦¬ë²„í’€ FC RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´")
        st.info("ìœ„í‚¤í”¼ë””ì•„ì˜ ë¦¬ë²„í’€ FC ê´€ë ¨ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.")
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ” ì§ˆë¬¸ ì…ë ¥")
        
        # ì„¸ì…˜ ìƒíƒœì—ì„œ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
        default_question = st.session_state.get('user_question', '')
        user_input = st.text_area(
            "ë¦¬ë²„í’€ FCì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”:",
            value=default_question,
            height=100,
            placeholder="ì˜ˆ: ë¦¬ë²„í’€ FCì˜ ì—­ì‚¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
        )
        
        # ì§ˆë¬¸ ì´ˆê¸°í™”
        if st.button("ì§ˆë¬¸ ì§€ìš°ê¸°"):
            st.session_state.user_question = ""
            st.rerun()
    
    with col2:
        st.subheader("âš™ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        with st.spinner("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
            rag_result = initialize_rag_system()
            
        if rag_result:
            rag_chain, doc_count = rag_result
            st.success("ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
            st.metric("ë¡œë“œëœ ë¬¸ì„œ ìˆ˜", doc_count)
        else:
            st.error("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return
    
    # ì§ˆë¬¸ ì²˜ë¦¬
    if user_input.strip():
        st.markdown("---")
        st.subheader("ğŸ’¬ ë‹µë³€")
        
        try:
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                # RAG ì²´ì¸ ì‹¤í–‰
                response = rag_chain.invoke(user_input)
                
            # ë‹µë³€ í‘œì‹œ
            st.write(response)

                
        except Exception as e:
            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    

if __name__ == "__main__":
    main()